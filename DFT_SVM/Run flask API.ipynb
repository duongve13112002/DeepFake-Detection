{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54691,"status":"ok","timestamp":1668752948930,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"},"user_tz":-420},"id":"6fjJNLMjwDxz","outputId":"b84d832a-6eec-43a1-afb6-786b85d85a7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7920,"status":"ok","timestamp":1668752979796,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"},"user_tz":-420},"id":"f6j_mIsHxCik","outputId":"471325f9-c85f-449b-f852-f0ed3195ad29"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyngrok\n","  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n","\u001b[K     |████████████████████████████████| 745 kB 7.0 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (6.0)\n","Building wheels for collected packages: pyngrok\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=bd0c51f918bcc8132a548ea17f45ac731e7acad881002cb6fc34f25f9606458c\n","  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n","Successfully built pyngrok\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-5.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting flask_ngrok\n","  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n"]}],"source":["!pip install pyngrok\n","!pip install flask_ngrok"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":889,"status":"ok","timestamp":1668753003298,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"},"user_tz":-420},"id":"DVF0q726xGN6","outputId":"4d0d272c-77c1-4324-c662-1f0551f1ff38"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/Final project\n"," anchors.npy\t      helpers\t\t     'Run flask API.ipynb'    video\n"," blazeface.pth\t      model\t\t      static\t\t      video_up\n"," FaceForensic.ipynb   Pre-Proccessing.ipynb   test_1000.pkl\n","'Flask API.ipynb'     README.md\t\t      train_3200.pkl\n","'Flask app .py'       requirements.txt\t     'Training model.ipynb'\n"]}],"source":["%cd \"/content/drive/MyDrive/Colab Notebooks/Final project\"\n","!ls "]},{"cell_type":"markdown","metadata":{"id":"t2eOjpSDz3Q1"},"source":["#  Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wc_gtWMHyhui"},"outputs":[],"source":["from flask import Flask, render_template, request, redirect, url_for\n","from keras.models import load_model\n","import numpy as np\n","import cv2\n","import os\n","from flask import Flask\n","from werkzeug.utils import secure_filename\n","import os\n","from tensorflow import keras\n","from flask import Flask, request, render_template\n","from werkzeug.utils import secure_filename\n","import dlib\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import img_to_array, load_img\n","from pyngrok import ngrok\n","from flask_ngrok import run_with_ngrok\n"]},{"cell_type":"markdown","metadata":{"id":"OIq5z1ECz0LV"},"source":["# Display Home Page "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v4aHMX8kyj3p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668753013436,"user_tz":-420,"elapsed":1543,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}},"outputId":"9bff5067-ea76-44ed-bacf-3f4d1040595e"},"outputs":[{"output_type":"stream","name":"stdout","text":[]}],"source":["app = Flask(__name__ , template_folder='static/templates')\n","ngrok.set_auth_token(\"29AhNyFJiBxEu0s07cR2zA8VqDQ_3wmwNStUSaHgpCiP2UNkd\")\n","run_with_ngrok(app)\n","@app.route('/')\n","def main():\n","  return render_template (\"Home.html\")"]},{"cell_type":"markdown","metadata":{"id":"_9LWfh85zvnR"},"source":["#  Redirect To Upload "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sh85xq7JymhB"},"outputs":[],"source":["\n","\n","@app.route('/upload_video', methods=['POST'])\n","def Video():\n","  return render_template (\"Upload_Video.html\")\n","\n","@app.route('/upload_image', methods=['POST'])\n","def image():\n","    return render_template('Upload_image.html')\n","@app.route('/About-us', methods=['POST'])\n","def About_us():\n","  return render_template('About-us.html')\n"]},{"cell_type":"markdown","metadata":{"id":"i3e4WK4gzsIO"},"source":["# Load Model "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Za9UHhU7yo6X"},"outputs":[],"source":["import joblib\n","path = '/content/drive/MyDrive/Colab Notebooks/Final Project/finalized_model.sav'\n","model = joblib.load(path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tYdyvq5GqEcx"},"outputs":[],"source":["import numpy as np\n","\n","def azimuthalAverage(image, center=None):\n","    \"\"\"\n","    Calculate the azimuthally averaged radial profile.\n","\n","    image - The 2D image\n","    center - The [x,y] pixel coordinates used as the center. The default is \n","             None, which then uses the center of the image (including \n","             fracitonal pixels).\n","    \n","    \"\"\"\n","    # Calculate the indices from the image\n","    y, x = np.indices(image.shape[:2])\n","\n","    if not center:\n","        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n","\n","    r = np.hypot(x - center[0], y - center[1])\n","\n","    # Get sorted radii\n","    ind = np.argsort(r.flat)\n","    r_sorted = r.flat[ind]\n","    i_sorted = image.flat[ind]\n","\n","    # Get the integer part of the radii (bin size = 1)\n","    r_int = r_sorted.astype(int)\n","\n","    # Find all pixels that fall within each radial bin.\n","    deltar = r_int[1:] - r_int[:-1]  # Assumes all radii represented\n","    rind = np.where(deltar)[0]       # location of changed radius\n","    nr = rind[1:] - rind[:-1]        # number of radius bin\n","    \n","    # Cumulative sum to figure out sums for each radius bin\n","    csim = np.cumsum(i_sorted, dtype=float)\n","    tbin = csim[rind[1:]] - csim[rind[:-1]]\n","\n","    radial_prof = tbin / nr\n","\n","    return radial_prof"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tqLlBS6y9aGO"},"outputs":[],"source":["import sys\n","import os\n","import torch\n","import cv2\n","import time\n","from torch import nn\n","import matplotlib.pyplot as plt\n","import matplotlib\n","from torchvision.transforms import Normalize\n","gpu = torch.device('cuda:0'if torch.cuda.is_available() else 'cpu')\n","gpu\n","\n","root = '/content/drive/MyDrive'\n","\n","frames_per_video = 100\n","input_size = 224\n","test_val_frac = 0.3\n","\n","sys.path.insert(0, os.path.join(root, 'Colab Notebooks', 'Final project', 'blazeface-pytorch'))\n","sys.path.insert(0, os.path.join(root, 'Colab Notebooks', 'Final project'))\n","\n","from blazeface import BlazeFace\n","facedet = BlazeFace().to(gpu)\n","facedet.load_weights(os.path.join(root, 'Colab Notebooks', 'Final project', \"blazeface.pth\"))\n","facedet.load_anchors(os.path.join(root, 'Colab Notebooks', 'Final project', \"anchors.npy\"))\n","\n","_ = facedet.train(False)\n","from helpers.read_video_1 import VideoReader\n","from helpers.face_extract_1 import FaceExtractor\n","\n","video_reader = VideoReader(verbose=True)\n","video_read_fn = lambda x: video_reader.read_frames(x, num_frames=frames_per_video)\n","face_extractor = FaceExtractor(video_read_fn, facedet)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IUo2LYdLBg-e"},"outputs":[],"source":["def add_margin_to_detections(detections, frame_size, margin=0.2):\n","        offset = torch.round(margin * (detections[:, 2] - detections[:, 0]))\n","        detections = detections.clone()\n","        detections[:, 0] = torch.clamp(detections[:, 0] - offset*2, min=0)            # ymin\n","        detections[:, 1] = torch.clamp(detections[:, 1] - offset, min=0)              # xmin\n","        detections[:, 2] = torch.clamp(detections[:, 2] + offset, max=frame_size[1])  # ymax\n","        detections[:, 3] = torch.clamp(detections[:, 3] + offset, max=frame_size[0])  # xmax\n","        return detections\n","    \n","def crop_faces(img, detections ):\n","    \"\"\"Copies the face region(s) from the given frame into a set\n","    of new NumPy arrays.\n","\n","    Arguments:\n","        frame: a NumPy array of shape (H, W, 3)\n","        detections: a PyTorch tensor of shape (num_detections, 17)\n","\n","    Returns a list of NumPy arrays, one for each face crop. If there\n","    are no faces detected for this frame, returns an empty list.\n","    \"\"\"\n","    faces = []\n","    for i in range(len(detections)):\n","        ymin, xmin, ymax, xmax = detections[i, :4].cpu().numpy()\n","        ymin = ymin * img.shape[0]\n","        xmin = xmin * img.shape[1]\n","        ymax = ymax * img.shape[0]\n","        xmax = xmax * img.shape[1]\n","        face = img[ymin.astype(np.int):ymax.astype(np.int), xmin.astype(np.int):xmax.astype(np.int), :]\n","        faces.append(face)\n","    return faces\n","\n","def keep_only_best_face(crops):\n","        for i in range(len(crops)):\n","            frame_data = crops[i]\n","            if len(frame_data[\"faces\"]) > 0:\n","                frame_data[\"faces\"] = frame_data[\"faces\"][:1]\n","                frame_data[\"scores\"] = frame_data[\"scores\"][:1]\n","\n","\n","def detec_and_crop_best_face(img_path):\n","  img = cv2.imread(img_path)\n","  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","  img = cv2.resize(img, facedet.input_size, interpolation = cv2.INTER_AREA)\n","\n","  target_size = facedet.input_size\n","  frame_size = (img.shape[1], img.shape[0])\n","\n","  detections = facedet.predict_on_image(img)\n","  faces = add_margin_to_detections(detections, frame_size, 0.5)\n","  scores = detections[:, 16].cpu().numpy()\n","\n","  faces = crop_faces(img, faces)\n","\n","  return faces[np.where(scores == np.amax(scores))[0][0]], scores[np.where(scores == np.amax(scores))[0][0]]"]},{"cell_type":"markdown","metadata":{"id":"o2OD7Uzkznx2"},"source":["# Function Prediction "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sbxbBnYYys_J"},"outputs":[],"source":["N = 500\n","from google.colab.patches import cv2_imshow\n","\n","from scipy.interpolate import griddata\n","def prediction_img (filepath, rate=0.1):\n","  img, score = detec_and_crop_best_face(filepath)\n","\n","  print(score)\n","  if(score < rate):\n","    return 'Không có mặt người trong ảnh'\n","  # we crop the center\n","  h = int(img.shape[0]/3)\n","  w = int(img.shape[1]/3)\n","  img = img[h:-h,w:-w]\n","\n","  f = np.fft.fft2(img)\n","  fshift = np.fft.fftshift(f)\n","\n","  magnitude_spectrum = 20*np.log(np.abs(fshift))\n","  psd1D = azimuthalAverage(magnitude_spectrum)\n","\n","  # Calculate the azimuthally averaged 1D power spectrum\n","  points = np.linspace(0,N,num=psd1D.size) # coordinates of a\n","  xi = np.linspace(0,N,num=N) # coordinates for interpolation\n","\n","  interpolated = griddata(points,psd1D,xi,method='cubic')\n","  interpolated /= interpolated[0]\n","  pre = model.predict([interpolated])\n","  if(pre == 1):\n","    return 'Real'\n","  else:\n","    return 'Fake'\n","\n","def prediction (filepath, rate =0.95):\n","  check = 0\n","  faces = face_extractor.process_video(filepath)\n","  face_extractor.keep_only_best_face(faces)\n","  if len(faces)>0:\n","    num=0\n","    for frame_data in faces:\n","      scores = frame_data['scores']\n","      for ind, img in enumerate(frame_data['faces']):\n","        if(scores[ind] > rate):\n","          # cv2_imshow(img)\n","          img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","          # cv2_imshow(img)\n","          h = int(img.shape[0]/3)\n","          w = int(img.shape[1]/3)\n","          img = img[h:-h,w:-w]\n","\n","          f = np.fft.fft2(img)\n","          fshift = np.fft.fftshift(f)\n","\n","          magnitude_spectrum = 20*np.log(np.abs(fshift))\n","          psd1D = azimuthalAverage(magnitude_spectrum)\n","\n","          # Calculate the azimuthally averaged 1D power spectrum\n","          points = np.linspace(0,N,num=psd1D.size) # coordinates of a\n","          xi = np.linspace(0,N,num=N) # coordinates for interpolation\n","\n","          interpolated = griddata(points,psd1D,xi,method='cubic')\n","          interpolated /= interpolated[0]\n","          if(int(model.predict([interpolated]))):\n","            check -=1\n","          else: check +=1\n","  if(check <0):\n","    return('Fake')\n","  else:\n","    return(\"Real\")"]},{"cell_type":"markdown","metadata":{"id":"w6hz6MmqzhB-"},"source":["# Upload File"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddpM762aywCo"},"outputs":[],"source":["UPLOAD_FOLDER = 'static'\n","app.secret_key = \"secret key\"\n","app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n","app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024"]},{"cell_type":"markdown","metadata":{"id":"Z3egqPL9zVM2"},"source":["#  Video Prediction & Display Result "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Xmm64H8yyk-"},"outputs":[],"source":["@app.route('/predict_video', methods=['POST'])\n","def upload_video():\n","\tfile = request.files['file']\n","\tfilename = secure_filename(file.filename)\n","\tfile.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n","\tfilepath = \"static/\"+filename\n","\tpreds = prediction(filepath)\n","\treturn render_template(\"Display_Video.html\",prediction =preds ,video_path = filename)"]},{"cell_type":"markdown","metadata":{"id":"vJ7JaIKezQyh"},"source":["# Image Prediction & Display Result "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"89tk41__y4CX"},"outputs":[],"source":["@app.route('/Predict_image', methods=['GET', 'POST'])\n","def upload():\n","    if request.method == 'POST':\n","        f = request.files['file']\n","        file_path = os.path.join (app.config['UPLOAD_FOLDER'], secure_filename(f.filename))\n","        f.save(file_path)\n","        \n","        preds = prediction_img(file_path)\n","    return render_template(\"Display_image.html\",prediction = preds, img_path= f.filename )\n"]},{"cell_type":"markdown","metadata":{"id":"0Up1IPIiy8VV"},"source":["# **Run Flask Application**#  "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obt5rbWmwun2","executionInfo":{"status":"ok","timestamp":1668756315677,"user_tz":-420,"elapsed":160269,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}},"outputId":"76068ae0-60b3-41ae-dc70-db1f7421bb03"},"outputs":[{"output_type":"stream","name":"stdout","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"]},{"output_type":"stream","name":"stdout","text":[" * Running on http://8df6-35-199-185-69.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:22:59] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:22:59] \"\u001b[37mGET /static/css/main.css HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:22:59] \"\u001b[37mGET /static/css/normalize.css HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:23:00] \"\u001b[37mGET /static/background/cover.mp4 HTTP/1.1\u001b[0m\" 206 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:23:00] \"\u001b[37mGET /static/background/cover.mp4 HTTP/1.1\u001b[0m\" 206 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:23:01] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:23:01] \"\u001b[37mGET /static/background/cover.mp4 HTTP/1.1\u001b[0m\" 206 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:23:12] \"\u001b[37mPOST /upload_image HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:23:12] \"\u001b[37mGET /static/js/jquery-1.12.4.min.js HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:23:12] \"\u001b[37mGET /static/js/main.js HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:23:13] \"\u001b[37mGET /static/css/aa.jpg HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:23:15] \"\u001b[37mPOST /upload_video HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:23:16] \"\u001b[37mGET /static/js/jquery-1.12.4.min.js HTTP/1.1\u001b[0m\" 206 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:23:16] \"\u001b[37mGET /static/css/aa.jpg HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:23:16] \"\u001b[37mGET /static/js/jquery-1.12.4.min.js HTTP/1.1\u001b[0m\" 206 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:23:33] \"\u001b[37mPOST /upload_video HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:24:23] \"\u001b[37mPOST /predict_video HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:24:24] \"\u001b[33mGET /js/jquery-1.12.4.min.js HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:24:24] \"\u001b[33mGET /js/main.js HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:24:24] \"\u001b[37mGET /static/Phuong_tien1.mp4 HTTP/1.1\u001b[0m\" 206 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:25:00] \"\u001b[37mPOST /predict_video HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:25:00] \"\u001b[33mGET /js/main.js HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:25:00] \"\u001b[33mGET /js/jquery-1.12.4.min.js HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [18/Nov/2022 07:25:00] \"\u001b[37mGET /static/Phuong_tien2.mp4 HTTP/1.1\u001b[0m\" 206 -\n"]}],"source":["if __name__ =='__main__': \n","  app.run()"]}],"metadata":{"colab":{"provenance":[{"file_id":"172wXMAcvo7wZnf0v5XAVtkBueBQOagf-","timestamp":1668484582136}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}